{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below is the code which groups the HomeAway's properties into different categories based on customer comments. It uses Latent Dirichlet Allocation (LDA) Model. \n",
    "\n",
    "In the LDA model, each document is viewed as a mixture of topics. The model proposes that each word in the document is attributable to one of the documentâ€™s topics. LDA gives us the proportion of different words associated with a particular topic. Based on the words associated with the topics, we defined 4 different groups - \"*Home Size*\", \"*Surrounding*\", \"*Amenities*\" and \"*Location*\". The LDA further discovered the proportion of different groups associated with a property. A property is classified into the group which is associated the most to it. \n",
    "\n",
    "The words which were most associated with each of the group (topic) are listed below. As can be seen below, LDA clearly clubbed similar words together into one group (topics) and separated out the distinguishable words into different groups (topics)\n",
    "\n",
    "\n",
    "**1. Home Size** - family, group, plenty, space, friends, party\n",
    "\n",
    "**2. Surroundings** - comfortable, quiet, beautiful, barton springs\n",
    "\n",
    "**3. Amenities** - kitchen, room, bed, towels, TV, parking, pool\n",
    "\n",
    "**4. Location** - downtown, south congress, 6th street, restaurants, food, bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with any of the empty columns:\n",
      "0\n",
      "provide the column name for property names: Property Link\n",
      "provide the column name for property reviews: Comments\n",
      "Provide the number of latent topics to be estimated: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lda:n_documents: 7795\n",
      "INFO:lda:vocab_size: 11929\n",
      "INFO:lda:n_words: 332533\n",
      "INFO:lda:n_topics: 4\n",
      "INFO:lda:n_iter: 500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7795, 11929)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bandi\\Anaconda3\\lib\\site-packages\\lda\\utils.py:55: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if sparse and not np.issubdtype(doc_word.dtype, int):\n",
      "INFO:lda:<0> log likelihood: -2966635\n",
      "INFO:lda:<10> log likelihood: -2661610\n",
      "INFO:lda:<20> log likelihood: -2584765\n",
      "INFO:lda:<30> log likelihood: -2544893\n",
      "INFO:lda:<40> log likelihood: -2524902\n",
      "INFO:lda:<50> log likelihood: -2512406\n",
      "INFO:lda:<60> log likelihood: -2505801\n",
      "INFO:lda:<70> log likelihood: -2502112\n",
      "INFO:lda:<80> log likelihood: -2499153\n",
      "INFO:lda:<90> log likelihood: -2497906\n",
      "INFO:lda:<100> log likelihood: -2495022\n",
      "INFO:lda:<110> log likelihood: -2494129\n",
      "INFO:lda:<120> log likelihood: -2494380\n",
      "INFO:lda:<130> log likelihood: -2492312\n",
      "INFO:lda:<140> log likelihood: -2492786\n",
      "INFO:lda:<150> log likelihood: -2491992\n",
      "INFO:lda:<160> log likelihood: -2492134\n",
      "INFO:lda:<170> log likelihood: -2492467\n",
      "INFO:lda:<180> log likelihood: -2490820\n",
      "INFO:lda:<190> log likelihood: -2491255\n",
      "INFO:lda:<200> log likelihood: -2491181\n",
      "INFO:lda:<210> log likelihood: -2490948\n",
      "INFO:lda:<220> log likelihood: -2491264\n",
      "INFO:lda:<230> log likelihood: -2490354\n",
      "INFO:lda:<240> log likelihood: -2489756\n",
      "INFO:lda:<250> log likelihood: -2489739\n",
      "INFO:lda:<260> log likelihood: -2490049\n",
      "INFO:lda:<270> log likelihood: -2490160\n",
      "INFO:lda:<280> log likelihood: -2491119\n",
      "INFO:lda:<290> log likelihood: -2490506\n",
      "INFO:lda:<300> log likelihood: -2490183\n",
      "INFO:lda:<310> log likelihood: -2490328\n",
      "INFO:lda:<320> log likelihood: -2490052\n",
      "INFO:lda:<330> log likelihood: -2489476\n",
      "INFO:lda:<340> log likelihood: -2488703\n",
      "INFO:lda:<350> log likelihood: -2489445\n",
      "INFO:lda:<360> log likelihood: -2490103\n",
      "INFO:lda:<370> log likelihood: -2490618\n",
      "INFO:lda:<380> log likelihood: -2489168\n",
      "INFO:lda:<390> log likelihood: -2489060\n",
      "INFO:lda:<400> log likelihood: -2489278\n",
      "INFO:lda:<410> log likelihood: -2488691\n",
      "INFO:lda:<420> log likelihood: -2489466\n",
      "INFO:lda:<430> log likelihood: -2489241\n",
      "INFO:lda:<440> log likelihood: -2488275\n",
      "INFO:lda:<450> log likelihood: -2488752\n",
      "INFO:lda:<460> log likelihood: -2488971\n",
      "INFO:lda:<470> log likelihood: -2488385\n",
      "INFO:lda:<480> log likelihood: -2488320\n",
      "INFO:lda:<490> log likelihood: -2487902\n",
      "INFO:lda:<499> log likelihood: -2489160\n"
     ]
    }
   ],
   "source": [
    "import os, csv, lda, nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import PunktSentenceTokenizer, RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from scipy import sparse\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from nltk.tokenize import PunktSentenceTokenizer,RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "reviews_df=pd.read_excel(\"comments_homeaway_final.xlsx\",encoding='utf8', errors='ignore')\n",
    "\n",
    "\n",
    "#checking for nulls if present any\n",
    "print(\"Number of rows with any of the empty columns:\")\n",
    "print(reviews_df.isnull().sum().sum())\n",
    "reviews_df=reviews_df.dropna() \n",
    "\n",
    "property_name = input('provide the column name for property names: ')\n",
    "property_review = input('provide the column name for property reviews: ')\n",
    "ntopics= input('Provide the number of latent topics to be estimated: ');\n",
    "\n",
    "\n",
    "word_tokenizer=RegexpTokenizer(r'\\w+')\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "stopwords_nltk=set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "def tokenize_text(version_desc):\n",
    "    lowercase=version_desc.lower()\n",
    "    text = wordnet_lemmatizer.lemmatize(lowercase)\n",
    "    tokens = word_tokenizer.tokenize(text)\n",
    "    return tokens\n",
    "\n",
    "vec_words = CountVectorizer(tokenizer=tokenize_text,stop_words=stopwords_nltk,decode_error='ignore')\n",
    "total_features_words = vec_words.fit_transform(reviews_df[property_review])\n",
    "\n",
    "print(total_features_words.shape)\n",
    "\n",
    "model = lda.LDA(n_topics=int(ntopics), n_iter=500, random_state=1)\n",
    "model.fit(total_features_words)\n",
    "\n",
    "topic_word = model.topic_word_ \n",
    "doc_topic=model.doc_topic_\n",
    "doc_topic=pd.DataFrame(doc_topic)\n",
    "reviews_df=reviews_df.join(doc_topic)\n",
    "properties=pd.DataFrame()\n",
    "\n",
    "for i in range(int(ntopics)):\n",
    "    topic=\"topic_\"+str(i)\n",
    "    properties[topic]=reviews_df.groupby([property_name])[i].mean()\n",
    "    \n",
    "properties=properties.reset_index()\n",
    "topics=pd.DataFrame(topic_word)\n",
    "topics.columns=vec_words.get_feature_names()\n",
    "topics1=topics.transpose()\n",
    "topics1.to_excel(\"topic_word_dist.xlsx\")\n",
    "properties.to_excel(\"properties_topic_dist.xlsx\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
